{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport gc\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tqdm.autonotebook import tqdm\nimport numpy as np\nimport pandas as pd\nfrom keras import Sequential\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.optimizers import Adam,SGD\nfrom keras.layers import Dense,Dropout,Flatten,BatchNormalization,Activation\nfrom keras.layers import Lambda,Input,GlobalAveragePooling2D,BatchNormalization\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\nfrom keras.preprocessing.image import load_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading labels csv file\nlabels = pd.read_csv('../input/dog-breed-identification/labels.csv')\nlabels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check one image\nfrom IPython.display import display,Image\nImage(\"../input/dog-breed-identification/train/00bee065dcec471f26394855c5c2f3de.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nif len(os.listdir('../input/dog-breed-identification/train')) == len(labels['id']):\n  print(\"Number of file matches of actual images!\")\nelse:\n  print(\"Number of file does not matches number of actual images!!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create list of alphabetical sorted labels.\nclasses = sorted(list(set(labels['breed'])))\nn_classes = len(classes)\nprint('Total unique breed {}'.format(n_classes))\n\n#Map each label string to an integer label.\nclass_to_num = dict(zip(classes, range(n_classes)))\nclass_to_num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (331,331,3)\n\ndef images_to_array(directory, label_dataframe,target_size = input_shape):\n  image_labels = label_dataframe['breed']\n  images = np.zeros([len(label_dataframe),target_size[0], target_size[1], target_size[2]], dtype=np.uint8)\n  y = np.zeros([len(label_dataframe),1],dtype=np.uint8)\n\n  for ix, image_name in enumerate(tqdm(label_dataframe['id'].values)):\n    img_dir = os.path.join(directory, image_name +'.jpg')\n    img = load_img(img_dir, target_size= target_size)\n    images[ix] = img\n    del img\n    dog_breed = image_labels[ix]\n    y[ix] = class_to_num[dog_breed]\n  y = to_categorical(y)\n  return images,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nt = time.time()\nx,y = images_to_array('../input/dog-breed-identification/train',labels[:])\nprint('runtime in seconds: {}'.format(time.time() - t))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check dog breeds\nn=36\n\n# setup the figure \nplt.figure(figsize=(20,20))\n\nfor i in range(n):\n#     print(i)\n    ax = plt.subplot(6, 6, i+1)\n    plt.title(classes[np.where(y[i] ==1)[0][0]])\n    plt.imshow(x[i].astype('int32'))\n           ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrr= ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5,verbose = 1)\n\n#Prepare call backs\nEarlyStop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameters\nbatch_size= 128\nepochs=50\nlearn_rate=.001\nsgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\nadam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None,  amsgrad=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to extract features from the dataset by a given pretrained model\nimg_size = (331,331,3)\n\ndef get_features(model_name, model_preprocessor, input_size, data):\n\n    input_layer = Input(input_size)\n    preprocessor = Lambda(model_preprocessor)(input_layer)\n    base_model = model_name(weights='imagenet', include_top=False,\n                            input_shape=input_size)(preprocessor)\n    avg = GlobalAveragePooling2D()(base_model)\n    feature_extractor = Model(inputs = input_layer, outputs = avg)\n    \n    #Extract feature.\n    feature_maps = feature_extractor.predict(data, verbose=1)\n    print('Feature maps shape: ', feature_maps.shape)\n    return feature_maps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract features using InceptionV3 \nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\ninception_preprocessor = preprocess_input\ninception_features = get_features(InceptionV3,\n                                  inception_preprocessor,\n                                  img_size, x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract features using Xception \nfrom keras.applications.xception import Xception, preprocess_input\nxception_preprocessor = preprocess_input\nxception_features = get_features(Xception,\n                                 xception_preprocessor,\n                                 img_size, x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract features using InceptionResNetV2 \nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\ninc_resnet_preprocessor = preprocess_input\ninc_resnet_features = get_features(InceptionResNetV2,\n                                   inc_resnet_preprocessor,\n                                   img_size, x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract features using NASNetLarge \nfrom keras.applications.nasnet import NASNetLarge, preprocess_input\nnasnet_preprocessor = preprocess_input\nnasnet_features = get_features(NASNetLarge,\n                               nasnet_preprocessor,\n                               img_size, x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del x #to free up some ram memory\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating final featuremap by combining all extracted features\n\nfinal_features = np.concatenate([inception_features,\n                                 xception_features,\n                                 nasnet_features,\n                                 inc_resnet_features,], axis=-1) #axis=-1 to concatinate horizontally\n\nprint('Final feature maps shape', final_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prepare Deep net\n\nmodel = Sequential()\n# model.add(Dense(1028,input_shape=(final_features.shape[1],)))\nmodel.add(Dropout(0.7,input_shape=(final_features.shape[1],)))\nmodel.add(Dense(n_classes,activation= 'softmax'))\n\nmodel.compile(optimizer=adam,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n#Training the model. \nhistory = model.fit(final_features, y,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_split=0.2,\n            callbacks=[lrr,EarlyStop])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#deleting to free up ram memory\n\ndel inception_features\ndel xception_features\ndel nasnet_features\ndel inc_resnet_features\ndel final_features\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def images_to_array_test(test_path, img_size = (331,331,3)):\n    test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n\n    data_size = len(test_filenames)\n    images = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)\n    \n    \n    for ix,img_dir in enumerate(tqdm(test_filenames)):\n#         img_dir = os.path.join(directory, image_name + '.jpg')\n        img = load_img(img_dir, target_size = img_size)\n#         img = np.expand_dims(img, axis=0)\n#         img = processed_image_resnet(img)\n#         img = img/255\n        images[ix]=img\n#         images[ix] = img_to_array(img)\n        del img\n    print('Ouptut Data Size: ', images.shape)\n    return images\n\ntest_data = images_to_array_test('../input/dog-breed-identification/test/', img_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extract test data features.\ndef extact_features(data):\n    inception_features = get_features(InceptionV3, inception_preprocessor, img_size, data)\n    xception_features = get_features(Xception, xception_preprocessor, img_size, data)\n    nasnet_features = get_features(NASNetLarge, nasnet_preprocessor, img_size, data)\n    inc_resnet_features = get_features(InceptionResNetV2, inc_resnet_preprocessor, img_size, data)\n\n    final_features = np.concatenate([inception_features,\n                                     xception_features,\n                                     nasnet_features,\n                                     inc_resnet_features],axis=-1)\n    \n    print('Final feature maps shape', final_features.shape)\n    \n    #deleting to free up ram memory\n    del inception_features\n    del xception_features\n    del nasnet_features\n    del inc_resnet_features\n    gc.collect()\n    \n    \n    return final_features\n\ntest_features = extact_features(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Free up some space.\ndel test_data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict test labels given test data features.\n\npred = model.predict(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First prediction\nprint(pred[0])\nprint(f\"Max value (probability of prediction): {np.max(pred[0])}\") # the max probability value predicted by the model\nprint(f\"Sum: {np.sum(pred[0])}\") # because we used softmax activation in our model, this will be close to 1\nprint(f\"Max index: {np.argmax(pred[0])}\") # the index of where the max value in predictions[0] occurs\nprint(f\"Predicted label: {classes[np.argmax(pred[0])]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create pandas DataFrame with empty columns\npreds_df = pd.DataFrame(columns=[\"id\"] + list(classes))\npreds_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Append test image ID's to predictions DataFrame\ntest_path = \"../input/dog-breed-identification/test/\"\npreds_df[\"id\"] = [os.path.splitext(path)[0] for path in os.listdir(test_path)]\npreds_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_df.loc[:,list(classes)]= pred\n\npreds_df.to_csv('submission.csv',index=None)\npreds_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Custom input\n\nImage('../input/dogbreedidentification/The-English-Cocker-Spaniel-HP-long.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading the image and converting it into an np array\n\nimg_g = load_img('../input/dogbreedidentification/The-English-Cocker-Spaniel-HP-long.jpg',target_size = img_size)\nimg_g = np.expand_dims(img_g, axis=0) # as we trained our model in (row, img_height, img_width, img_rgb) format, np.expand_dims convert the image into this format\n# img_g","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_g.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict test labels given test data features.\ntest_features = extact_features(img_g)\npredg = model.predict(test_features)\nprint(f\"Predicted label: {classes[np.argmax(predg[0])]}\")\nprint(f\"Probability of prediction): {round(np.max(predg[0])) * 100} %\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}